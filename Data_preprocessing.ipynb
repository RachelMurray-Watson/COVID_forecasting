{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data processing to get cases, deaths, hospitalizations, change in hospitalizations, and admissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%reset\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta \n",
    "\n",
    "\n",
    "hfont = {'fontname':'Helvetica'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_prep_dates(dataset, columns, date_column, start_date, number_weeks, is_weeks):\n",
    "    \"\"\"\n",
    "    Takes data frame with daily or weekly data and subsets rows between two dates. \n",
    "    \"\"\"\n",
    "\n",
    "    dataset = dataset[columns]\n",
    "\n",
    "    dataset = dataset.sort_values(date_column).reset_index(drop=True)\n",
    "\n",
    "    dataset['index'] = range(len(dataset[date_column]))\n",
    "    start_date_row = dataset[dataset[date_column] == start_date]['index'].min()\n",
    "\n",
    "    start_date_index_dates = int(np.where(dataset[date_column].unique() == start_date)[0])\n",
    "    if is_weeks: \n",
    "        six_month_date_index_dates = dataset[date_column].unique()[number_weeks + start_date_index_dates]\n",
    "    else:\n",
    "            six_month_date_index_dates = dataset[date_column].unique()[(number_weeks * 7) + start_date_index_dates]\n",
    "\n",
    "    end_date_row = dataset[dataset[date_column] == six_month_date_index_dates]['index'].max()\n",
    "    dataset = dataset[start_date_row:end_date_row]\n",
    "    return(dataset)\n",
    "\n",
    "def weekly_date_range(dataset):\n",
    "    dataset['date'] = pd.to_datetime(dataset['date'])\n",
    "\n",
    "    start_date = dataset['date'].min()\n",
    "    end_date = dataset['date'].max()\n",
    "    dates = []\n",
    "    current_date = start_date\n",
    "\n",
    "    while current_date <= end_date:\n",
    "        dates.append(current_date)\n",
    "        current_date += timedelta(days=7)\n",
    "    return dates\n",
    "\n",
    "def convert_state_name_to_abbreviation(state_name):\n",
    "    state_name = state_name.lower().strip()\n",
    "\n",
    "    state_abbreviations = {\n",
    "        'alabama': 'AL',\n",
    "        'alaska': 'AK',\n",
    "        'arizona': 'AZ',\n",
    "        'arkansas': 'AR',\n",
    "        'california': 'CA',\n",
    "        'colorado': 'CO',\n",
    "        'connecticut': 'CT',\n",
    "        'delaware': 'DE',\n",
    "        'florida': 'FL',\n",
    "        'georgia': 'GA',\n",
    "        'hawaii': 'HI',\n",
    "        'idaho': 'ID',\n",
    "        'illinois': 'IL',\n",
    "        'indiana': 'IN',\n",
    "        'iowa': 'IA',\n",
    "        'kansas': 'KS',\n",
    "        'kentucky': 'KY',\n",
    "        'louisiana': 'LA',\n",
    "        'maine': 'ME',\n",
    "        'maryland': 'MD',\n",
    "        'massachusetts': 'MA',\n",
    "        'michigan': 'MI',\n",
    "        'minnesota': 'MN',\n",
    "        'mississippi': 'MS',\n",
    "        'missouri': 'MO',\n",
    "        'montana': 'MT',\n",
    "        'nebraska': 'NE',\n",
    "        'nevada': 'NV',\n",
    "        'new hampshire': 'NH',\n",
    "        'new jersey': 'NJ',\n",
    "        'new mexico': 'NM',\n",
    "        'new york': 'NY',\n",
    "        'north carolina': 'NC',\n",
    "        'north dakota': 'ND',\n",
    "        'ohio': 'OH',\n",
    "        'oklahoma': 'OK',\n",
    "        'oregon': 'OR',\n",
    "        'pennsylvania': 'PA',\n",
    "        'rhode island': 'RI',\n",
    "        'south carolina': 'SC',\n",
    "        'south dakota': 'SD',\n",
    "        'tennessee': 'TN',\n",
    "        'texas': 'TX',\n",
    "        'utah': 'UT',\n",
    "        'vermont': 'VT',\n",
    "        'virginia': 'VA',\n",
    "        'washington': 'WA',\n",
    "        'washington dc': 'DC',\n",
    "        'west virginia': 'WV',\n",
    "        'wisconsin': 'WI',\n",
    "        'wyoming': 'WY',\n",
    "        'district of columbia': 'DC'\n",
    "    }\n",
    "\n",
    "    return state_abbreviations.get(state_name, None)\n",
    "\n",
    "def convert_daily_weekly(dataset, column_name, date_column, geography_column):\n",
    "    dataset[date_column] = pd.to_datetime(dataset[date_column])\n",
    "\n",
    "    dates = weekly_date_range(dataset)\n",
    "\n",
    "    num_rows = len(dates)*len(dataset[geography_column].unique())\n",
    "    weekly_dataframe = pd.DataFrame(columns=dataset.columns[range(len(column_name))], index=range(num_rows))\n",
    "    weekly_dataframe.columns = column_name\n",
    "\n",
    "    x = -1\n",
    "    for geography in dataset[geography_column].unique():\n",
    "        state_data = dataset[dataset[geography_column] == geography].reset_index()\n",
    "        for date in dates: \n",
    "            x += 1\n",
    "            weekly_dataframe.iloc[x,1] = geography\n",
    "            weekly_dataframe.iloc[x,0] = date\n",
    "            if (state_data.loc[0, 'date'] < date) | (state_data.loc[0, 'date'] <= (date - timedelta(days=7))):\n",
    "                end_index = state_data.loc[state_data['date'] < date, 'date'].idxmax()\n",
    "                start_index = state_data.loc[(state_data['date'] <= (date - timedelta(days=7))), 'date'].idxmax()\n",
    "                selected_rows = state_data.iloc[start_index:end_index, len(state_data.columns)-1]\n",
    "                cumulative_sum = selected_rows.sum()\n",
    "                weekly_dataframe.iloc[x,2] = cumulative_sum\n",
    "\n",
    "    return(weekly_dataframe)\n",
    "\n",
    "def per_100k(dataset, date_column, value_column, geography_column, categories_to_create, populations, hospitalizations, threshold ):\n",
    "    geography_names = dataset[geography_column].unique()\n",
    "    dataset = dataset.pivot_table(index= date_column, columns=geography_column, values=value_column) # gets rid of week - 2 \n",
    "    dataset = dataset.reset_index()\n",
    "    for geography in geography_names: \n",
    "        for column in categories_to_create:\n",
    "            col_name_rate = geography + column\n",
    "            dataset[col_name_rate] = dataset[geography]/populations[geography] * 100000\n",
    "            col_name_delta = geography + '_delta_100k'\n",
    "            j = 0\n",
    "            for row in range(len(dataset[geography]) - 1): ## need to use j as an index as row is a datetime object \n",
    "                    if(j != 0):\n",
    "                        dataset.loc[j, col_name_delta] = dataset.loc[j, col_name_rate] - dataset.loc[j - 1, col_name_rate]\n",
    "                    j+=1\n",
    "    if hospitalizations: \n",
    "            col_name_threshold = geography + '_over_' + str(threshold) + '_100k'\n",
    "            dataset[col_name_threshold] = (dataset[col_name_rate] > threshold)*1\n",
    "    # remove first row with week - 1\n",
    "    dataset = dataset[dataset[date_column] != dataset.loc[0,date_column] ] ## remove week 0 \n",
    "\n",
    "    return(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "population_by_state_April_2020 = {\n",
    "    'Alabama': 5024279,\n",
    "    'Alaska': 733391,\n",
    "    'Arizona': 7151502,\n",
    "    'Arkansas': 3011524,\n",
    "    'California': 39538223,\n",
    "    'Colorado': 5773714,\n",
    "    'Connecticut': 3605944,\n",
    "    'Delaware': 989948,\n",
    "    'District of Columbia': 689545,\n",
    "    'Florida': 21538187,\n",
    "    'Georgia': 10711908,\n",
    "    'Hawaii': 1455271,\n",
    "    'Idaho': 1839106,\n",
    "    'Illinois': 12812508,\n",
    "    'Indiana': 6785528,\n",
    "    'Iowa': 3190369,\n",
    "    'Kansas': 2937880,\n",
    "    'Kentucky': 4505836,\n",
    "    'Louisiana': 4657757,\n",
    "    'Maine': 1362359,\n",
    "    'Maryland': 6177224,\n",
    "    'Massachusetts': 7029917,\n",
    "    'Michigan': 10077331,\n",
    "    'Minnesota': 5706494,\n",
    "    'Mississippi': 2961279,\n",
    "    'Missouri': 6154913,\n",
    "    'Montana': 1084225,\n",
    "    'Nebraska': 1961504,\n",
    "    'Nevada': 3104614,\n",
    "    'New Hampshire': 1377529,\n",
    "    'New Jersey': 9288994,\n",
    "    'New Mexico': 2117522,\n",
    "    'New York': 20201249,\n",
    "    'North Carolina': 10439388,\n",
    "    'North Dakota': 779094,\n",
    "    'Ohio': 11799448,\n",
    "    'Oklahoma': 3959353,\n",
    "    'Oregon': 4237256,\n",
    "    'Pennsylvania': 13002700,\n",
    "    'Rhode Island': 1097379,\n",
    "    'South Carolina': 5118425,\n",
    "    'South Dakota': 886667,\n",
    "    'Tennessee': 6910840,\n",
    "    'Texas': 29145505,\n",
    "    'Utah': 3271616,\n",
    "    'Vermont': 643077,\n",
    "    'Virginia': 8631393,\n",
    "    'Washington': 7705281,\n",
    "    'West Virginia': 1793716,\n",
    "    'Wisconsin': 5893718,\n",
    "    'Wyoming': 576851\n",
    "}\n",
    "population_by_state_April_2020_abb = {}\n",
    "states_to_remove = []\n",
    "\n",
    "for state_name in population_by_state_April_2020:\n",
    "    state_abbreviation = convert_state_name_to_abbreviation(state_name)\n",
    "    if state_abbreviation:\n",
    "        population_by_state_April_2020_abb[state_abbreviation] = population_by_state_April_2020[state_name]\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data from https://healthdata.gov/Hospital/COVID-19-Reported-Patient-Impact-and-Hospital-Capa/g62h-syeh\n",
    "- Hospitalizations\n",
    "- Use total adult patients with covid and total pediatric patients with covid for total covid cases\n",
    "- Try and plot to match up \n",
    "- Also has previous day admissions - can try and get cumulative over 7 days to match with weekly admissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "State_hospitalizations = pd.read_csv(\"/Users/rem76/Documents/COVID_projections/COVID-19_Reported_Patient_Impact_and_Hospital_Capacity_by_State_Timeseries__RAW_.csv\")\n",
    "# Remove non-states (except DC)\n",
    "\n",
    "State_hospitalizations = State_hospitalizations[(State_hospitalizations['state'] != 'PR') & (State_hospitalizations['state'] != 'VI') & (State_hospitalizations['state'] != 'GU')& (State_hospitalizations['state'] != 'AS')& (State_hospitalizations['state'] != 'MP')]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall hospital numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/d4/chxwf4hs5kq7ttsp56s64z65mjk3qj/T/ipykernel_45414/18807921.py:13: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  start_date_index_dates = int(np.where(dataset[date_column].unique() == start_date)[0])\n"
     ]
    }
   ],
   "source": [
    "State_hospitalizations_total_hospitalizations = data_prep_dates(State_hospitalizations, columns = ['date', 'state', 'percent_of_inpatients_with_covid_numerator'], date_column = 'date', start_date = '2020/06/21', number_weeks = 26, is_weeks = False)\n",
    "## Start date is two week before the actual date of interest, allows us to calculate the weekly and change in weekly rate for our \"actual\" first week "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "State_hospitalizations_total_hospitalizations = State_hospitalizations_total_hospitalizations[['date', 'state', 'percent_of_inpatients_with_covid_numerator']]\n",
    "State_hospitalizations_total_hospitalizations.rename(columns={'percent_of_inpatients_with_covid_numerator': 'case_numbers'}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "State_hospitalizations_total_hospitalizations_weekly = convert_daily_weekly(State_hospitalizations_total_hospitalizations, ['date', 'state', 'case_numbers'], 'date', 'state')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/d4/chxwf4hs5kq7ttsp56s64z65mjk3qj/T/ipykernel_45414/18807921.py:128: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataset[col_name_rate] = dataset[geography]/populations[geography] * 100000\n",
      "/var/folders/d4/chxwf4hs5kq7ttsp56s64z65mjk3qj/T/ipykernel_45414/18807921.py:133: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataset.loc[j, col_name_delta] = dataset.loc[j, col_name_rate] - dataset.loc[j - 1, col_name_rate]\n",
      "/var/folders/d4/chxwf4hs5kq7ttsp56s64z65mjk3qj/T/ipykernel_45414/18807921.py:128: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataset[col_name_rate] = dataset[geography]/populations[geography] * 100000\n",
      "/var/folders/d4/chxwf4hs5kq7ttsp56s64z65mjk3qj/T/ipykernel_45414/18807921.py:133: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataset.loc[j, col_name_delta] = dataset.loc[j, col_name_rate] - dataset.loc[j - 1, col_name_rate]\n",
      "/var/folders/d4/chxwf4hs5kq7ttsp56s64z65mjk3qj/T/ipykernel_45414/18807921.py:137: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataset[col_name_threshold] = (dataset[col_name_rate] > threshold)*1\n"
     ]
    }
   ],
   "source": [
    "State_hospitalizations_total_hospitalizations_weekly = per_100k(State_hospitalizations_total_hospitalizations_weekly, date_column = 'date', value_column = 'case_numbers', geography_column = 'state', categories_to_create = ['hospitalizations'],populations =  population_by_state_April_2020_abb, hospitalizations = True, threshold = 15 )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "COVID_forecasting",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a72d884e172d11118bfdfb578e108fb6b63a679c74d3d7d2f9d493a9a72737c0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
