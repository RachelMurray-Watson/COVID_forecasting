{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%reset\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from num2words import num2words\n",
    "from sklearn.model_selection import RandomizedSearchCV, cross_val_score, KFold, RepeatedStratifiedKFold\n",
    "from sklearn.metrics import f1_score, matthews_corrcoef, roc_auc_score\n",
    "import word2number\n",
    "from word2number import w2n\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "#oversample = RandomOverSampler(sampling_strategy = 0.5,random_state=10) #need for neural network and random forest\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/d4/chxwf4hs5kq7ttsp56s64z65mjk3qj/T/ipykernel_8100/3165355871.py:1: DtypeWarning: Columns (41,43,44,45,46,50,51) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data_by_HSA = pd.read_csv('/Users/rem76/Documents/COVID_projections/hsa_time_data_all_dates.csv')\n"
     ]
    }
   ],
   "source": [
    "data_by_HSA = pd.read_csv('/Users/rem76/Documents/COVID_projections/hsa_time_data_all_dates.csv')\n",
    "data_by_HSA['health_service_area_number']\n",
    "data_by_HSA['health_service_area']\n",
    "#data_by_HSA['HSA_ID'] = data_by_HSA['health_service_area_number'].astype(str) + '' + data_by_HSA['health_service_area'].apply(lambda x: x.split()[0])\n",
    "data_by_HSA.rename(columns={'health_service_area_number': 'HSA_ID'}, inplace=True)\n",
    "\n",
    "data_by_HSA['beds_over_15_100k'] = (data_by_HSA['beds_weekly'] > 15)*1\n",
    "\n",
    "# remove HSAs that have missing data in specific columns\n",
    "\n",
    "data_by_HSA = data_by_HSA.dropna(subset=['admits_weekly', 'deaths_weekly', 'cases_weekly', 'icu_weekly', 'beds_weekly', 'perc_covid'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_and_rename_data(data1, data2, on_column, suffix1, suffix2):\n",
    "    merged_data = pd.merge(data1, data2, on=on_column, suffixes=('_'+suffix1, '_'+suffix2))\n",
    "\n",
    "    new_column_names = [col.replace(f'_{on_column}_{suffix1}', f'_{suffix1}').replace(f'_{on_column}_{suffix2}', f'_{suffix2}') for col in merged_data.columns]\n",
    "    merged_data.rename(columns=dict(zip(merged_data.columns, new_column_names)), inplace=True)\n",
    "\n",
    "    return merged_data\n",
    "\n",
    "def pivot_data_by_HSA(data, index_column, columns_column, values_column):\n",
    "    data_by_HSA = data[[index_column, columns_column, values_column]]\n",
    "    pivot_table = data_by_HSA.pivot_table(index=index_column, columns=columns_column, values=values_column)\n",
    "    return pivot_table\n",
    "\n",
    "def create_column_names(categories_for_subsetting, num_of_weeks):\n",
    "    column_names = ['HSA_ID']\n",
    "\n",
    "    for week in range(1, num_of_weeks + 1):\n",
    "        week = num2words(week)\n",
    "        for category in categories_for_subsetting:\n",
    "            column_name = f'week_{week}_{category}'\n",
    "            column_names.append(column_name)\n",
    "\n",
    "    return column_names\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rename weeks so 7/10/2022 is the first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, week in enumerate(data_by_HSA['date'].unique()):\n",
    "    data_by_HSA.loc[data_by_HSA['date'] == week, 'week'] = i"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## pivot \n",
    "data_by_HSA_cases = pivot_data_by_HSA(data_by_HSA, 'week', 'HSA_ID', 'cases_weekly')\n",
    "data_by_HSA_deaths = pivot_data_by_HSA(data_by_HSA, 'week', 'HSA_ID', 'deaths_weekly')\n",
    "data_by_HSA_admissions = pivot_data_by_HSA(data_by_HSA, 'week', 'HSA_ID', 'admits_weekly')\n",
    "data_by_HSA_icu = pivot_data_by_HSA(data_by_HSA, 'week', 'HSA_ID', 'icu_weekly')\n",
    "data_by_HSA_beds = pivot_data_by_HSA(data_by_HSA, 'week', 'HSA_ID', 'beds_weekly')\n",
    "data_by_HSA_percent_beds = pivot_data_by_HSA(data_by_HSA, 'week', 'HSA_ID', 'perc_covid')\n",
    "data_by_HSA_over_15_100k = pivot_data_by_HSA(data_by_HSA, 'week', 'HSA_ID', 'beds_over_15_100k')\n",
    "\n",
    "## merge \n",
    "data_by_HSA_cases_deaths = merge_and_rename_data(data_by_HSA_cases, data_by_HSA_deaths,'week','cases', 'deaths')\n",
    "data_by_HSA_admits_icu_weekly = merge_and_rename_data(data_by_HSA_admissions, data_by_HSA_icu,'week','admits', 'icu')\n",
    "data_by_HSA_beds_perc_weekly = merge_and_rename_data(data_by_HSA_beds, data_by_HSA_percent_beds,'week','beds', 'perc_covid')\n",
    "data_by_HSA_cases_deaths_admits_icu = pd.merge(data_by_HSA_cases_deaths, data_by_HSA_admits_icu_weekly, on='week')\n",
    "\n",
    "## add outcome variable \n",
    "\n",
    "old_column_names = data_by_HSA_over_15_100k.columns\n",
    "new_column_names = [str(col) + '_beds_over_15_100k' for col in old_column_names]\n",
    "new_column_names = dict(zip(old_column_names, new_column_names))\n",
    "data_by_HSA_over_15_100k.rename(columns=new_column_names, inplace=True)\n",
    "data_by_HSA_cases_deaths_admits_icu_beds = pd.merge(data_by_HSA_cases_deaths_admits_icu, data_by_HSA_over_15_100k, on='week')\n",
    "\n",
    "data_by_HSA_cases_deaths_admits_icu_beds = data_by_HSA_cases_deaths_admits_icu_beds.reset_index()\n",
    "data_by_HSA_cases_deaths_admits_icu_beds.columns = data_by_HSA_cases_deaths_admits_icu_beds.columns.str.replace(',', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories_for_subsetting = ['cases', 'deaths', 'admit', 'icu', 'beds', 'beds_over_15_100k']\n",
    "num_of_weeks = len(data_by_HSA_cases_deaths_admits_icu_beds)\n",
    "column_names = create_column_names(categories_for_subsetting, num_of_weeks)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "COVID_forecasting",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a72d884e172d11118bfdfb578e108fb6b63a679c74d3d7d2f9d493a9a72737c0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
